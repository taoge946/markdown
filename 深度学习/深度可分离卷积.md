# 深度可分离卷积

#### 正常卷积：

对于一张5×5像素、三通道（shape为5×5×3），经过3×3卷积核的卷积层（假设输出通道数为4，则卷积核shape为3×3×3×4，最终输出4个Feature Map，如果有same padding则尺寸与输入层相同（5×5），如果没有则为尺寸变为3×3

![img](https://pic1.zhimg.com/80/v2-617b082492f5c1c31bde1c6e2d994bc0_720w.jpg)

卷积层共4个Filter，每个Filter包含了3个Kernel，每个Kernel的大小为3×3。因此卷积层的参数数量可以用如下公式来计算：

```python 
N_std = 4 × 3 × 3 × 3 = 108
```



#### 深度可分离卷积

- 逐通道卷积

Depthwise Convolution的一个卷积核负责一个通道，一个通道只被一个卷积核卷积

一张5×5像素、三通道彩色输入图片（shape为5×5×3），Depthwise Convolution首先经过第一次卷积运算，DW完全是在二维平面内进行。卷积核的数量与上一层的通道数相同（通道和卷积核一一对应）。所以一个三通道的图像经过运算后生成了3个Feature map(如果有same padding则尺寸与输入层相同为5×5)，如下图所示。

其中一个Filter只包含一个大小为3×3的Kernel，卷积部分的参数个数计算如下：

```python
N_depthwise = 3 × 3 × 3 = 27
```

Depthwise Convolution完成后的Feature map数量与输入层的通道数相同，无法扩展Feature map。而且这种运算对输入层的每个通道独立进行卷积运算，没有有效的利用不同通道在相同空间位置上的feature信息。因此需要*Pointwise Convolution(逐点卷积)*来将这些Feature map进行组合生成新的Feature map



![img](https://pic4.zhimg.com/80/v2-a20824492e3e8778a959ca3731dfeea3_720w.jpg)

- 逐点卷积

Pointwise Convolution的运算与常规卷积运算非常相似，它的卷积核的尺寸为 1×1×M，M为上一层的通道数。所以这里的卷积运算会将上一步的map在深度方向上进行加权组合，生成新的Feature map。有几个卷积核就有几个输出Feature map



![img](https://pic4.zhimg.com/80/v2-2cdae9b3ad2f1d07e2c738331dac6d8b_720w.jpg)

由于采用的是1×1卷积的方式，此步中卷积涉及到的参数个数可以计算为：

```python 
N_pointwise = 1 × 1 × 3 × 4 = 12
```

经过Pointwise Convolution之后，同样输出了4张Feature map，与常规卷积的输出维度相同

#### 参数对比

```python
常规卷积：N_std = 4 × 3 × 3 × 3 = 108
深度可分离卷积：
N_depthwise = 3 × 3 × 3 = 27
N_pointwise = 1 × 1 × 3 × 4 = 12
N_separable = N_depthwise + N_pointwise = 39
```

相同的输入，同样是得到4张Feature map，Separable Convolution的参数个数是常规卷积的约1/3。因此，在参数量相同的前提下，采用Separable Convolution的神经网络层数可以做的更深。

#### 结论

简言之，就是把普通的卷积拆分成两个，第一个用（h, w, input__channel）来减小模型参数，第二个用（h, w, output_channel）来加深模型通道。作用有点类似GoogLeNet中的1x1卷积

会使参数的数量显著减少使得层数可以更深但会降低准确率