# s图片输入深度学习模型的方式

```python
from PIL import Image #pytorch中读取图片的方法都是使用这个Image
from torchvision import transforms#使用transforms进行图片的转换，再使用plt进行绘图
import glob #获取所有图片的路径
```
## 1.使用imagefloder

4种天气分类哪个实验中我们使用`train_ds=torchvision.datasets.ImageFolder()`来读取数据图片的，这种方式也比较方便，但缺点就是数据集必须将相同的类别划分到相同的文件夹中，而且得手动划分训练集和测试集。

```python
train_ds=torchvision.datasets.ImageFolder(
    train_dir,                      #两个参数，一个是目录地址，一个是变形方法
    transform=train_transform  

)
text_ds=torchvision.datasets.ImageFolder(
    text_dir,                      #两个参数，一个是目录地址，一个是变形方法
    transform=test_transform  

)
```

## 2.通过dataset子类

```python
from torch.utils import data    #先引入data

#必须创建两个方法    #__getitem__ 这个方法可以使这个类可以切片
                  #__len__ 方法，能够返回数据集的长度
                  #__init__初始化方法，告诉类输入图片的路径等等参数
class Mydataset(data.Dataset):   #必须从dataset中继承，创建一个子类
    def __init__(self,root) :
        self.imgs_path=root  #图片路径
    def __getitem__(self,index): #index索引的位置
        img_path=self.imgs_path[index]  #进行切片
        return img_path
    def __len__(self):
        return len(self.imgs_path)    #返回dataset的长度

```

模型需要一个图片地址来进行输入，我们可以使用python的标准库glob来获取所有指定地址下的期望内容

```python
import glob #glob方法可以获取某一个条件下的所有路径

all_image_path=glob.glob(r'D:\python\weather_dataset\*.jpg') #这样就获取到了这个路径下面所有以.jpg结尾的文件，返回的是路径
#如果想寻找指定类别的图片则可以
all_image_path=glob.glob(r'D:\python\weather_dataset\rain*.jpg')
```

然后就可以创建一个类来进行操作了。模型实例化（初始化）时需要输入所有图片的路径

```python
weather_dataset=Mydataset(all_image_path)

#可以测试设置的两个方法都是可以正常使用的
len(weather_dataset)
weather_dataset[23]  
```

这个类是继承dataset类，可以直接转变成dataloader

```python
from torch.utils.data import DataLoader

dl=DataLoader(weather_dataset,batch_size=4)
```

以上仅仅是获得了输入图片的路径，我们还需要获得输入图片的标签

```python
speices=['cloudy','rain','shine','sunrise']
speices_to_idx=dict((c,i) for i,c in enumerate(speices))#将各种类别转化为数字表示  enumerate()会返回一个对应位置 两个参数就是第一个是序号第二个是名称
                                                        #再调换个顺序，使得输出为 cloudy:1
idx_to_speces=dict((v,k) for k,v in speices_to_idx.items()) #通过序号去找图片类别
#按字典定义可以使用.get()方法根据序号获取种类或根据种类获取序号如idx_to_speces.get(2)=shine
# 													   speices_to_idx.get('rain')=1


all_labels=[]  #用来按顺序储存所有标签的序号
for img in all_image_path:#此时all_image_path中的内容为指定文件夹中的所有图片的位置，img就是每一张图片的名称（位置）
    for i,c in enumerate(speices): #默认enumerate的第一个参数是序号，第二个参数是其中的值。
       if c in img:   #字符串的应用，查看某一个字符串中是否包含指定的字符串 
        			  #如果当前类别（4种天气，c）在当前图片的名称中，就将其序号（i）写入标签组中
           all_labels.append(i)

```

这样`all_labels`中就存上了0,1,2,3这四种标签了

![image-20210915162327814](C:\Users\tao'ge\AppData\Roaming\Typora\typora-user-images\image-20210915162327814.png)

现在就获取了所有的图片路径以及所有的标签，接下来就可以创建输入

先创建一个transform（*以下同图像数据增强*）

```python
from torchvision import transforms

train_transform=transforms.Compose([
    transforms.Resize((244,244)), #先裁剪成一个大一点的图片再随机裁剪成192x192的
    transforms.RandomCrop(192),#随机裁剪成192的
    transforms.RandomHorizontalFlip(),#加一个随机的左右翻转
    transforms.RandomRotation(0.2),#随机旋转20度   
    transforms.ColorJitter(brightness=0.5),#随机调整亮度，0.5是超参数，需要自己去更改
    transforms.ColorJitter(contrast=0.5),#随机调整对比度
    transforms.ColorJitter(saturation=0.5)#随机调整饱和度
    transforms.ColorJitter(hue=0.5)#随机调整颜色
    transforms.RandomGrayscale(p=0.5)#随机灰度化
    transforms.ToTensor(),#规范到0到1之间 ,将维度提到最前面，将图片转化为tensor格式，必须加这个变形 。必须放在最后Normalize之前，否则会报错
    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]) #标准化   从0~1转化成-1~1  
                                #两个参数分别是均值和方差，如果事先了解数据集的可以直接填上，不了解就写个大概
                                #当模型出现过拟合时，用来降低模型的复杂度
])
#可以不用这么多的变形
transform=transforms.Compose([
    transforms.Resize((96,96)), #一定要这么口号带括号的resize 
    transforms.ToTensor()
])   
```

再重新创建子类，将标签和定义的变形方法加入自己定义的dataset子类中，再将其进行升级

```python
class Mydataset(data.Dataset):
    def __init__(self,img_paths,label,transform): #将标签和变形方法也放入初始化中
        self.imgs=img_paths
        self.labels=label    #将标签
        self.transform=transform  #以及图像变换方法进行初始化
    def __getitem__(self,index):  #不再只是将图片的路径返回了，而是进行图片的读取转换之后再返回
        img=self.imgs[index]
        label=self.labels[index]   #同时也将标签切片

        pil_img=Image.open(img) #python里最重要的图像处理的库，用它来读取图片（将图片的地址信息到图片的内容）
        data=self.transform(pil_img)#这就是已经转换好的图像数据了

        return data,label
    def __len__(self):
        return len(self.imgs)
```

根据这个类来创建输入图片数据的dataset集

```python
weather_dataset=Mydataset(all_image_path,all_labels,transform)
weather_dl=DataLoader(weather_dataset,batch_size=16,shuffle=True,)
```

可以看一下切片切出来的一片`imgs_batch,label_batch=next(iter(weather_dl))`,符合预期

<img src="C:\Users\tao'ge\AppData\Roaming\Typora\typora-user-images\image-20210915210524678.png" alt="image-20210915210524678" style="zoom:100%;" />

可以将切片的图像显示出来

```python
plt.figure(figsize=(12,8))  #创建个大一点的画布
for i,(img,label) in enumerate(zip(imgs_batch[:6],label_batch[:6])):  # i是序号
    img=(img.permute(1,2,0).numpy() ) #对图像进行变换使其可以被显示，将原本的第0个通道（通道数）放到最后
    plt.subplot(2,3,i+1)  #子图一共2行三列，当次放在第i+1个子图上
    plt.title(idx_to_speces.get(label.item())) 
    							#.get()就是获得对应的类别名称（这就是为什么之前要定义字典并将序号和名称换位置）
        						#.item()获取其数值
    plt.imshow(img)
```

![image-20210915211506962](C:\Users\tao'ge\AppData\Roaming\Typora\typora-user-images\image-20210915211506962.png)

不仅仅图片数据可以根据创建子类来进行数据的输入，csv，ndarry等数据都可以通过创建dataset的子类来进行操作。



但是有时输入的图片维度不一定一致，比如一堆RGB图片中混入了几张灰度图片，

（RGB图像是3维的，分别是H，W，C；灰度图像是二维的，没有通道数那个维度）

此时我们就要人为的将它转化为维度为3 的图片，先拓展这个黑白图像的维度，重复3次

```python
class birds(data.Dataset):
    def __init__(self,images_path,label):
        super().__init__()
        self.labels=label
        self.imgs=images_path
    def __getitem__(self, index) :
       img=self.imgs[index]
       labels=self.labels[index]
       pil_img=Image.open(img) 
       #若图片是灰度图片，就需要人为的给他添加维度
       #彩色图片的shape有3个，为H,W,C。灰度图片只有H,W,shape是2
       np_img=np.asarray(pil_img,dtype=np.uint8)#先转换成numpy格式的方便使用
       if len(np_img.shape)==2:
           img_data=np.repeat(np_img[:,:,np.newaxis],3,axis=2)#添加一个值为1的新的维度，将最后一个维度重复三次
           pil_img=Image.fromarray(img_data)#再转换成pil_image形式
       img_tensor=transforms(pil_img)
       return img_tensor,labels
    def __len__(self):
        return len(self.imgs)

```







在此之后我们还要创建***训练和测试数据集***

划分过程的创建之处与原本的并没有改变，只是在处理输入的路径时使用列表的一些技巧，将他们划分成训练数据和测试数据

首先将图片和标签进行相同的乱序，保证乱序后标签和图像还是一一对应的。

首先还是需要上述步骤读入所有图像。

***乱序和划分方法：***

```python
index=np.random.permutation(len(all_image_path)) 
								#这种方法会返回乱序的输入值，比如括号里是3那就会0，1，2乱序返回如2，0，1等

all_image_path=np.array(all_image_path)[index] #使用的是numpy的方法，所以使用之前要先化成ndarray类型，再乱序赋值
all_labels=np.array(all_labels)[index] 
#这样就完成乱序了，然后再划分训练和测试数据集就可以了

s=int(len(all_image_path)*0.8)#选取80%的图像作为训练集

train_imgs=all_image_path[:s]
train_labels=all_labels[:s]
test_imgs=all_image_path[s:]
test_labels=all_labels[s:] #这么划分的前提是对数据集做乱序
```

然后根据分好的图片分别创建测试和验证ds，dl

```python
rain_ds=Mydataset(train_imgs,train_labels,transform)
test_ds=Mydataset(test_imgs,test_labels,transform)
train_dl=DataLoader(train_ds,batch_size=16,shuffle=True)
trest_dl=DataLoader(test_ds,batch_size=16)
```

> 这种通过子类化来处理数据十分的灵活，自己需要什么功能就往子类中添加就可以了

接下来通过一个例子来实现通过创建dataset子类来灵活的加载数据

比如我们使用了一个别人创建好的dataload但是其中的图片数据是channel放在最前面的，我们想把他放到最后面
